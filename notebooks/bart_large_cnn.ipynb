{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BART LARGE CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import torch\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "import spacy\n",
    "\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartTokenizerFast\n",
    "from transformers import logging as T_LOGGER\n",
    "T_LOGGER.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "\n",
    "from transformers import BigBirdPegasusForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-pubmed\")\n",
    "\n",
    "# by default encoder-attention is `block_sparse` with num_random_blocks=3, block_size=64\n",
    "model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-pubmed\")\n",
    "\n",
    "# decoder attention type can't be changed & will be \"original_full\"\n",
    "# you can change `attention_type` (encoder only) to full attention like this:\n",
    "# model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-pubmed\", attention_type=\"original_full\")\n",
    "\n",
    "# you can change `block_size` & `num_random_blocks` like this:\n",
    "# model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-pubmed\", block_size=16, num_random_blocks=2)\n",
    "\n",
    "\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "prediction = model.generate(**inputs)\n",
    "prediction = tokenizer.batch_decode(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checkpoint = \"google/bigbird-pegasus-large-pubmed\"  # NO\n",
    "# checkpoint = \"knkarthick/MEETING_SUMMARY\" # interessante\n",
    "# checkpoint = \"philschmid/bart-large-cnn-samsum\" # sembra molto simile al normale bart-large-cnn ma pi√π grosso\n",
    "# checkpoint = \"facebook/bart-large-cnn\"\n",
    "\n",
    "# tokenizer = BartTokenizerFast.from_pretrained(checkpoint)\n",
    "# model = BartForConditionalGeneration.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_summary_pegasus(sentence, model, tokenizer):\n",
    "    input_ids = tokenizer(sentence, return_tensors='pt')\n",
    "    preds = model.generate(**input_ids)\n",
    "    preds = tokenizer.batch_decode(preds)\n",
    "    return preds\n",
    "\n",
    "def get_summary(sentence, model, tokenizer):\n",
    "    input_ids = tokenizer.encode(sentence, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    preds = model.generate(input_ids, **model.config.task_specific_params['summarization'])\n",
    "    return tokenizer.decode(preds[0], skip_special_tokens=True)\n",
    "\n",
    "def get_nest_sentences(document: str, tokenizer: AutoTokenizer, token_max_length = 1024):\n",
    "    \"\"\"\n",
    "    Starting from a large document, a list of sequential string is computed, such that each string has\n",
    "    a number of tokens equal to token_max_length.\n",
    "\n",
    "    ---Params\n",
    "    - document: the long text (str)\n",
    "    - tokenizer: the pre-trained tokenizer to be used.\n",
    "    - token_max_length: the maximum number of token has required by the NLP model (int)\n",
    "    \"\"\"\n",
    "    sents = []\n",
    "    length = 0\n",
    "    doc = nlp(document)\n",
    "    s = ''\n",
    "    for sentence in doc.sents:\n",
    "        # print(f'Sentence: {sentence}')\n",
    "        tokens_in_sentence = tokenizer(str(sentence), truncation=False, padding=False)[0]\n",
    "        length += len(tokens_in_sentence) # how many tokens the current sentence have summed to the previous\n",
    "        # print(f'length: {length}')\n",
    "        if length <= token_max_length:\n",
    "            s += sentence.text\n",
    "        else:\n",
    "            sents.append(s)\n",
    "            s = sentence.text\n",
    "            length = 0\n",
    "    # append last string with less # of tokens than token_max_length\n",
    "    sents.append(s)\n",
    "    print(f'Returning {len(sents)} number of chunk strings')\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"\"\"Solar physics is the branch of astrophysics that specializes in the study of the Sun. \n",
    "It deals with detailed measurements that are possible only for our closest star. It intersects with many disciplines of pure physics, \n",
    "astrophysics, and computer science, including fluid dynamics, plasma physics including magnetohydrodynamics, seismology, particle physics, atomic physics, nuclear physics, \n",
    "stellar evolution, space physics, spectroscopy, radiative transfer, applied optics, signal processing, computer vision, computational physics, stellar physics and solar astronomy.\n",
    "\n",
    "Because the Sun is uniquely situated for close-range observing (other stars cannot be resolved with anything like the spatial or temporal resolution that the Sun can), \n",
    "there is a split between the related discipline of observational astrophysics (of distant stars) and observational solar physics.\n",
    "\n",
    "The study of solar physics is also important as it provides a \"physical laboratory\" for the study of plasma physics. Babylonians were keeping a record of solar eclipses, \n",
    "with the oldest record originating from the ancient city of Ugarit, in modern-day Syria. This record dates to about 1300 BC.[2] Ancient Chinese astronomers were also observing solar phenomena \n",
    "(such as solar eclipses and visible sunspots) with the purpose of keeping track of calendars, which were based on lunar and solar cycles. \n",
    "Unfortunately, records kept before 720 BC are very vague and offer no useful information.\n",
    "However, after 720 BC, 37 solar eclipses were noted over the course of 240 years. Astronomical knowledge flourished in the Islamic world during medieval times. \n",
    "Many observatories were built in cities from Damascus to Baghdad, where detailed astronomical observations were taken. Particularly, a few solar parameters were measured \n",
    "and detailed observations of the Sun were taken. Solar observations were taken with the purpose of navigation, but mostly for timekeeping. Islam requires its followers \n",
    "to pray five times a day, at specific position of the Sun in the sky. As such, accurate observations of the Sun and its trajectory on the sky were needed. \n",
    "In the late 10th century, Iranian astronomer Abu-Mahmud Khojandi built a massive observatory near Tehran. There, he took accurate measurements of a series of meridian transits of the Sun, \n",
    "which he later used to calculate the obliquity of the ecliptic.[4] \n",
    "Following the fall of the Western Roman Empire, Western Europe was cut from all sources of ancient scientific knowledge, \n",
    "especially those written in Greek. This, plus de-urbanisation and diseases such as the Black Death led to a decline in scientific knowledge in Medieval Europe, \n",
    "especially in the early Middle Ages. During this period, observations of the Sun were taken either in relation to the zodiac, or to assist in building places \n",
    "of worship such as churches and cathedrals. \n",
    "In astronomy, the renaissance period started with the work of Nicolaus Copernicus. \n",
    "He proposed that planets revolve around the Sun and not around the Earth, as it was believed at the time. \n",
    "This model is known as the heliocentric model.[6] His work was later expanded by Johannes Kepler and Galileo Galilei. \n",
    "Particularly, Galilei used his new telescope to look at the Sun. \n",
    "In 1610, he discovered sunspots on its surface. In the autumn of 1611, Johannes Fabricius wrote the first book on sunspots, De Maculis in Sole Observatis (\"On the spots observed in the Sun\").\n",
    "Modern day solar physics is focused towards understanding the many phenomena observed with the help of modern telescopes and satellites. \n",
    "Of particular interest are the structure of the solar photosphere, \n",
    "the coronal heat problem and sunspots. \n",
    "\n",
    "The Solar Physics Division of the American Astronomical Society boasts 555 members (as of May 2007), \n",
    "compared to several thousand in the parent organization.[8]\n",
    "A major thrust of current (2009) effort in the field of solar physics is integrated understanding of the entire Solar System including the Sun and its effects \n",
    "throughout interplanetary space within the heliosphere and on planets and planetary atmospheres. Studies of phenomena that affect multiple systems in the heliosphere, \n",
    "or that are considered to fit within a heliospheric context, are called heliophysics, a new coinage that entered usage in the early years of the current millennium.\n",
    "Helios-A and Helios-B are a pair of spacecraft launched in December 1974 and January 1976 from Cape Canaveral, as a joint venture between the German Aerospace Center and NASA. \n",
    "Their orbits approach the Sun closer than Mercury. They included instruments to measure the solar wind, \n",
    "magnetic fields, cosmic rays, and interplanetary dust. Helios-A continued to transmit data until 1986\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, format='%(asctime)-15s %(message)s',\n",
    "                level=logging.INFO, datefmt=None)\n",
    "logger = logging.getLogger(\"Summarizer\")\n",
    "\n",
    "\n",
    "from operator import attrgetter\n",
    "from collections import Counter, namedtuple\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "\n",
    "m1 = \"\"\"\n",
    "Solar physics is the branch of astrophysics that specializes in the study of the Sun.\n",
    "It deals with detailed measurements that are possible only for our closest star.It intersects with many disciplines of pure physics, astrophysics, and computer science, \n",
    "including fluid dynamics, plasma physics including magnetohydrodynamics, seismology, particle physics, atomic physics, nuclear physics, \n",
    "stellar evolution, space physics, spectroscopy, radiative transfer, applied optics, signal processing, computer vision, computational physics, stellar physics and solar astronomy.\n",
    "Because the Sun is uniquely situated for close-range observing (other stars cannot be resolved with anything like the spatial or temporal resolution that the Sun can), \n",
    "there is a split between the related discipline of observational astrophysics (of distant stars) and observational solar physics. The study of solar physics is also important \n",
    "as it provides a \"physical laboratory\" for the study of plasma physics.Babylonians were keeping a record of solar eclipses, \n",
    "with the oldest record originating from the ancient city of Ugarit, in modern-day Syria.This record dates to about 1300 BC.\n",
    "Ancient Chinese astronomers were also observing solar phenomena \\n(such as solar eclipses and visible sunspots) with the purpose of keeping track of calendars, \n",
    "which were based on lunar and solar cycles.\\nUnfortunately, records kept before 720 BC are very vague and offer no useful information.\n",
    "However, after 720 BC, 37 solar eclipses were noted over the course of 240 years.Astronomical knowledge flourished in the Islamic world during medieval times.\n",
    "Many observatories were built in cities from Damascus to Baghdad, where detailed astronomical observations were taken.Particularly, a few solar parameters were measured \n",
    "and detailed observations of the Sun were taken.\n",
    "\"\"\"\n",
    "SentenceInfo = namedtuple(\"SentenceInfo\", (\"sentence\", \"order\", \"rates\",))\n",
    "\n",
    "def get_significant_words_list(doc: spacy.tokens.doc.Doc) -> List[str]:\n",
    "   \"\"\"\n",
    "   Get a list contained words that are important for the speech (PROPN; ADJ; NOUN; VERB): excluding stop words, punctations\n",
    "   \"\"\"\n",
    "   words = []\n",
    "   stopwords = list(STOP_WORDS)\n",
    "   pos_tag = ['PROPN', 'ADJ', 'NOUN', 'VERB']\n",
    "   for token in doc:\n",
    "       if (token.text in stopwords or token.text in punctuation):\n",
    "           continue\n",
    "       if (token.pos_ in pos_tag):\n",
    "           words.append(token.text)\n",
    "   return words\n",
    "\n",
    "def get_frequency_words(words: List[str]) -> Counter:\n",
    "   \"\"\"Get a counter with the frequency of each word normalized to one.\"\"\"\n",
    "   freq_word = Counter(words)\n",
    "   max_freq = freq_word.most_common(1)[0][1]\n",
    "   for word in freq_word.keys():\n",
    "       freq_word[word] = (freq_word[word] / max_freq)\n",
    "   return freq_word\n",
    "   \n",
    "def get_sent_strenght(doc: spacy.tokens.doc.Doc, freq_word: Counter) -> Dict:\n",
    "    \"\"\"Get a dictionary where the keys are sentence (str) and the values are float indicating the importance score of the sentence, based on most high frequencies words.\"\"\"\n",
    "    sent_strenght = {}\n",
    "    for sent in doc.sents:\n",
    "        for word in sent:\n",
    "            if word.text in freq_word.keys():\n",
    "                if sent in sent_strenght.keys():\n",
    "                    sent_strenght[sent] += freq_word[word.text]\n",
    "                else:\n",
    "                    sent_strenght[sent] = freq_word[word.text]\n",
    "    return sent_strenght\n",
    "\n",
    "def get_extractive_summary(sent_strenght: Dict, n_sents: int = 5):\n",
    "    infos = (SentenceInfo(s, o, sent_strenght.get(s)) \n",
    "        for o, s in enumerate(sent_strenght.keys()))\n",
    "\n",
    "    infos = sorted(infos, key=attrgetter(\"rates\"), reverse=True)[:n_sents]\n",
    "    infos = sorted(infos, key=attrgetter(\"order\"))\n",
    "    logger.info(f\"Extracted {len(infos)} sentences ...\")\n",
    "    return tuple(i.sentence.text for i in infos)\n",
    "\n",
    "\n",
    "def extractive_summary_pipeline(doc: str, n_sents: int = 5) -> str:\n",
    "    \"\"\"Get a final summary of a doc, using a maximum number n_sents of top sentences.\"\"\"\n",
    "    doc = nlp(doc)\n",
    "    logger.info(f\"Starting to compute summary from {len(list(doc.sents))} sentences ...\")\n",
    "    words = get_significant_words_list(doc)\n",
    "    freq_word = get_frequency_words(words)\n",
    "    sent_strenght = get_sent_strenght(doc, freq_word)\n",
    "\n",
    "    summaries = get_extractive_summary(sent_strenght, n_sents=n_sents)\n",
    "    start_sentence = list(doc.sents)[0].text\n",
    "    total_summary = ' '.join(summaries)\n",
    "    if start_sentence in summaries:\n",
    "        return total_summary\n",
    "    return start_sentence + total_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = extractive_summary_pipeline(doc=message, n_sents=5)\n",
    "print(summaries)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ebb7f5bbb98572b15bff58c8aed07b0a474ef83fd7734f6b950989757680d4c6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venvML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
