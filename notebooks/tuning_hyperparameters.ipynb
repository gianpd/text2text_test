{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, learning_curve, validation_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'https://archive.ics.uci.edu/ml/'\n",
    "    'machine-learning-databases'\n",
    "    '/breast-cancer-wisconsin/wdbc.data',\n",
    "    header=None\n",
    ")\n",
    "df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X, y = df.iloc[:, 2:].values, df.iloc[:, 1].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "le.classes_\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=.2, stratify=y, random_state=1\n",
    ")\n",
    "len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combing preprocessing and final model in a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PCA(n_components=2),\n",
    "    LogisticRegression()\n",
    ")\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "test_acc = pipe_lr.score(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation:\n",
    "Nel processo di tuning degli iperparametri del modello, è cruciale non usare sempre lo stesso dataset di test, perchè questo porterebbe a trovare una soluzione ottima con alto bias.\n",
    "La corretta procedura, invece, deve essere quella di usare un dataset di *validation* estratto dal dataset di training. Una possibilità sarebbe quella di usare la tecnica del *holdout*, in cui il dataset totale viene suddiviso in 3 sotto insiemi: [train, validation, test], in genere con percentuali del tipo [70%, 10%, 20%], rispettivamente. Tuttavia, questa tecnica dipende fortemente dal unico modo utilizzato per splittare il dataset.\n",
    "\n",
    "Una pratica ancora più performante è la tecnica dello *Stratified Cross-Validation*. In tale tecnica, il dataset iniziale viene suddivo in train e test, successivamente (in fase di *evaluation*) il dataset di train viene suddiviso in K *folds*, per cui K-1 vengono usati come dataset di training e il K-esimo come validation. La procedura viene ripetuta un numero K di volte, in cui il K-esimo dataset di validation è sempre differente dal caso precedente. Lo score finale sarà ottenuto prendendo la media delle K iterazioni. Inoltre, il metodo assicura che, in ogni iterazione il numero delle classi rimane constante (*stratified*), in modo da trainare i K modelli, in situazioni simili, per quanto riguarda il numero di labels.\n",
    "\n",
    "A fine della procedura, viene trainato un unico modello, usando le configurazioni degli iperparametri ottimi, ed utilizzando l'intero dataset di training (train + validation == 80% dei dati) e usando il dataset di test (mai utilizzato finora) per valutare l'errore di generalizzazione. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "KFold = StratifiedKFold(n_splits=10).split(X_train, y_train)\n",
    "\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(KFold):\n",
    "    _ = pipe_lr.fit(X_train[train], y_train[train])\n",
    "    scores.append(pipe_lr.score(X_train[test], y_train[test]))\n",
    "    print(\n",
    "        f'Fold {k+1:02} '\n",
    "        f'Class distr. : {np.bincount(y_train[train])} '\n",
    "        f'CV score: {scores[-1]:.3f}')\n",
    "\n",
    "\n",
    "print(f'CV accuracy averaged: {np.mean(scores):.3f} +/- {np.std(scores):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same thing, but less verbose ...\n",
    "scores = cross_val_score(\n",
    "    estimator=pipe_lr,\n",
    "    X=X_train, \n",
    "    y=y_train,\n",
    "    cv=10, # 10-folds \n",
    "    n_jobs=-1 # exploits all available cpus\n",
    ")\n",
    "print(f'CV accuracy scores:\\n{scores}\\n')\n",
    "print(f'CV accuracy: {np.mean(scores):.3f} +/- {np.std(scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation curve\n",
    "La validation curve visualizza l'accuratezza, sul dataset di training e di validation, al variare dei valori di alcuni iperparametri del modello. Il suo plot aiuta ad individuare, in modo grafico, il range di valori entro i quali, gli iperparametri danno un accuratezza sul validation test ottima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_curve(estimator, X, y, param_range, param_name, cv=10):\n",
    "    \"\"\"Validation curve plot: shows accuracy values for different values of a select parameters.\n",
    "    \n",
    "    --Params\n",
    "     - estimator: a scikit-learn estimator,\n",
    "     - X, y: numpy ndarrays\n",
    "     - param_range: List, the range values the paramete must explor\n",
    "     - param_name: str, the name of the parameter\n",
    "     -cv: int, the number of folds for the stratified cross validation\n",
    "     \"\"\"\n",
    "    \n",
    "    train_score, test_score = validation_curve(\n",
    "        estimator=estimator,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        param_range=param_range,\n",
    "        param_name=param_name,\n",
    "        cv=cv\n",
    "    )\n",
    "\n",
    "    train_avg, train_std = np.mean(train_score, axis=1), np.std(train_score, axis=1)\n",
    "    test_avg, test_std = np.mean(test_score, axis=1), np.std(test_score, axis=1)\n",
    "    \n",
    "    plt.plot(param_range, train_avg, color='blue', marker='o', markersize=5, label='Training Accuracy')\n",
    "    plt.fill_between(param_range, train_avg + train_std, train_avg - train_std, alpha=.15, color='blue')\n",
    "    plt.plot(param_range, test_avg, color='green', marker='s', markersize=5, linestyle='--', label='Validation Accuracy')\n",
    "    plt.fill_between(param_range, test_avg + test_std, test_avg - test_std, alpha=.15, color='green')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel(f\"Parameter {param_name.split('__')[-1]}\")\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0.8, 1.0])\n",
    "    plt.xscale('log')\n",
    "    plt.show()\n",
    "\n",
    "pipe_lr = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(penalty='l2', max_iter=10000)\n",
    ")\n",
    "plot_validation_curve(pipe_lr, X_train, y_train, [0.001, 0.01, 0.1, 1.0, 10.0, 100.0], 'logisticregression__C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "Un modello di ML ha due tipi di parametri: i parametri imparati durante la fase di training (weights, bias), e dei parametri che definiscono il modello e sono impostati in fase di progettazione (learning-rate, penalization values, il max depth number in un albero decisionale). Questi ultimi, vanno tunati al fine di rintracciare l'insieme di valori ottimi, in termini di accuratezza del modello, per questo si chiamano hyperparameters. \n",
    "\n",
    "La Grid Search è una tecnica *brute-force* esaustiva, che permette di trovare la combinazione di parametri ottimali, semplicemente provandone tutte le possibili combinazioni. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe_svc = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(random_state=1)\n",
    ")\n",
    "\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [\n",
    "    {'svc__C': param_range,\n",
    "    'svc__kernel': ['linear']},\n",
    "\n",
    "    {'svc__C': param_range,\n",
    "    'svc__gamma': param_range,\n",
    "    'svc__kernel': ['rbf']}]\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe_svc,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=10,\n",
    "    refit=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs = grid.fit(X_train, y_train)\n",
    "gs.best_score_\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = gs.best_estimator_\n",
    "_ = clf.fit(X_train, y_train)\n",
    "print(f'Test accuracy: {clf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search\n",
    "Il metodo del grid search essendo un metodo *esaustivo* rintraccia la combinazione ottima degli iperparametri, tuttavia diventa ostico poterlo applicare quando ci sono più di 3 parametri da ottimizzare (too computational expensive), i parametri da ottimizzare possono assumere valori continui (molti valori saranno trascurati).\n",
    "Inoltre, tutti i valori che si andranno ad esplorare sono fissati in modo deterministico, pertanto non esplorati in modo uniforme. \n",
    "\n",
    "La tecnica del random search, permette di migliorare le performance rispetto a questi punti. I valori da esplorare per gli iperarametri sono estratti da una distribuzione di probabilità (uniforme o altro tipo), e questo assicura di esplorare i valori in modo meno sistematico e quindi più efficiente *(un esplorazione degli iperparametri random è statisticamente più efficiente di una deterministica *Random Search for Hyper-Parameter Optimization by J. Bergstra, Y. Bengio, Journal of Machine Learning \n",
    "Research, pp. 281-305, 2012*)* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = scipy.stats.loguniform(0.0001, 1000.0)\n",
    "param_range.rvs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {\"svc__C\": param_range,\n",
    "    \"svc__kernel\": [\"linear\"]},\n",
    "    {\"svc__C\": param_range,\n",
    "    \"svc__gamma\": param_range,\n",
    "    \"svc__kernel\": [\"rbf\"]}\n",
    "]\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=pipe_svc,\n",
    "    param_distributions=param_grid, # note the *ditributions part\n",
    "    scoring='accuracy',\n",
    "    refit=True,\n",
    "    n_iter=20,\n",
    "    cv=10,\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "_ = rs.fit(X_train, y_train)\n",
    "rs.best_score_\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notare come, l'uso del random search e quindi l'uso di una funzione di ditribuzione per il parametro c, ha permesso di rintracciare un valore di C, altrimenti escluso nella ricerca con il grid search, rintracciando una configuarazione ottimale più semplice (a livello computazionale più efficiente) ma che apporta grosso modo lo stesso valore di accuratezza, in fase di test, come si vede sotto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = rs.best_estimator_\n",
    "_ = clf.fit(X_train, y_train)\n",
    "print(f'Test accuracy: {clf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Halving random search\n",
    "\n",
    "Stesso concetto del random search, ma, usa le risorse (il dataset) in modo incrementale: inizia con tutti i candidati utilizzando metà del dataset, in successive iterazioni, seleziona solo i migliori candidati e incrementa il dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è una features sperimentale: bisogna importare questa macro, perchè l'API potrebbe cambiare senza deprecation cycle\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "# adesso importa il metodo\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "\n",
    "hs = HalvingRandomSearchCV(\n",
    "    estimator=pipe_svc,\n",
    "    param_distributions=param_grid,\n",
    "    n_candidates='exhaust', # scegli un numero di candidati tale da sfruttare tutto il dataset\n",
    "    resource='n_samples',\n",
    "    factor=1.5, # quanti candidati saranno scartati ad ogni iterazione (100%/1.5=66% rimarranno)\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "_ = hs.fit(X_train, y_train)\n",
    "hs.best_score_\n",
    "hs.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = hs.best_estimator_\n",
    "_ = clf.fit(X_train, y_train)\n",
    "print(f'Test accuracy: {clf.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venvML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebb7f5bbb98572b15bff58c8aed07b0a474ef83fd7734f6b950989757680d4c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
