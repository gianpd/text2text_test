{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar correction models explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAMFORMER_MODEL_URL = \"prithivida/grammar_error_correcter_v1\"\n",
    "grammar_model, grammar_tokenizer = utils.load_s2s_model(GRAMFORMER_MODEL_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influent_sentences = [\n",
    "    \"He are moving here.\",\n",
    "    \"I am doing fine. How is you?\",\n",
    "    \"Anna and Mike is going skiing\",\n",
    "    \"I walk to the store and I bought milk\",\n",
    "    \"We all eat the fish and then made dessert\",\n",
    "    \"what be the reason for everyone leave the company\",\n",
    "    \"Is you sure?\",\n",
    "    \"Are he sure?\",\n",
    "]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5: Text To Text Transfer Transformer:\n",
    "Many tasks are cast into this framework: machine translation, classification task, regression task ( for example, predict how similar two sentences are, the similarity score is in range 1 to 5), other sequence to sequence tasks like document summarization (for example, summarising articles from CNN daily mail corpus).\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"t5_img.png\"  width=500>\n",
    "    <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"T5 uses common crawl web extracted text. The authors apply some pretty simple heuristic filtering. \n",
    "T5 removes any lines that didnâ€™t end in a terminal punctuation mark. \n",
    "It also removes line with the word javascript and any pages that had a curly bracket (since it often appears in code). \n",
    "It deduplicates the dataset by taking a sliding window of 3 sentence chunks and deduplicated \n",
    "it so that only one of them appeared the dataset. For example, above 3 pages, \n",
    "the last paragraph on the middle page is removed since the same content appears on the first page. \n",
    "It ends up with 750 gigabytes of clean-ish English text. \n",
    "The dataset is publicly available on tensorlow.text.c4.\"\"\"\n",
    "c = utils.grammar_correct(s, grammar_model, grammar_tokenizer, prefix='summarize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"How many channels are there for each cell\"\n",
    "corrected = utils.grammar_correct(s, grammar_model, grammar_tokenizer)\n",
    "corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*a summarized version of the initial corpus.*\n",
    "\n",
    "<p>\n",
    "\n",
    "**HERE**, it is used as a grammar corrector.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in influent_sentences:\n",
    "    print(f'Incorrect: {sentence}')\n",
    "    corrected = utils.grammar_correct(sentence, grammar_model, grammar_tokenizer)\n",
    "    print(f\"Predicted: {corrected.pop()}\")\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOW** we apply the grammar model to an md file composed of several lines, which we split and analyze\n",
    "separatly, because the model has a maximum number of characters as input size (max_lenght=128)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('grammar_exploration.md', 'r') as f:\n",
    "    texts = f.read()\n",
    "texts = texts.split('\\n')\n",
    "tobe_corrected = set()\n",
    "for line in texts:\n",
    "    ls = re.split(r\"\\.|\\?|\\!\", line)\n",
    "    for l in ls:\n",
    "        tobe_corrected.add(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tobe_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in tobe_corrected:\n",
    "    if s not in ('', ' ', '<br>', '<p>', '</b>'):\n",
    "        print(f'Incorrect: {s}')\n",
    "        corrected = utils.grammar_correct(s, grammar_model, grammar_tokenizer)\n",
    "        print(f\"Predicted: {corrected.pop()}\")\n",
    "        print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-Answering models exploration\n",
    "\n",
    "Question-Answering NLP models are able, given a context and a question, to extract the relevant part of the context\n",
    "which answers the requested question. We use a tiny version (130 MB) of the ROBERTA-SQUAD2 model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepset/tinyroberta-squad2\"\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions = ['What is the definition of an adjoint operator?',\n",
    "#             'What is the definition of an unitary operator?',\n",
    "#             'Is T=T* a self-adjoint operator?']\n",
    "\n",
    "# context = \"\"\"Let T be an operator over an Hilbert space, its adjoint T* is defined by (Tx,y)=(x,T*y).\\n\n",
    "#              When T=T* then T is a self-adjoint operator.\\n \n",
    "#            An unitary operator U is such that UU*=U*U=I, where U* is its adjoint, and I is the identity operator.\"\"\"\n",
    "\n",
    "questions = [\"Where are used self-adjoint operators?\", \"Why are self-adjoint operators important in quantum mechanics?\"] \n",
    "context = \"\"\"\n",
    "Self-adjoint operators are used in functional analysis and quantum mechanics. \n",
    "In quantum mechanics their importance lies in the Dirac-von Neumann formulation of quantum mechanics, \n",
    "in which physical observables such as position, energy, angular momentum, spin, are represented by \n",
    "self-adjoint operators on a Hilbert space. Let T be an operator over an Hilbert space, \n",
    "its adjoint T* is defined by (Tx,y)=(x,T*y).\\n\n",
    "When T=T* then T is a self-adjoint operator.\\n \n",
    "An unitary operator U is such that UU*=U*U=I, where U* is its adjoint, and I is the identity operator.\n",
    "\"\"\"\n",
    "\n",
    "# for q in questions:\n",
    "#     qa = {'question': q, 'context': context}\n",
    "#     res = nlp(qa)\n",
    "#     print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp2 = pipeline('question-answering', \n",
    "#         model='bert-large-uncased-whole-word-masking-finetuned-squad',\n",
    "#         tokenizer='bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "# for q in questions:\n",
    "#     qa = {'question': q, 'context': context}\n",
    "#     res = nlp2(qa)\n",
    "#     print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_model, qa_tokenizer = utils.load_qa_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Widgets for grammar and question-answering models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual(\n",
    "    sentence='How are angular momentum represented in quantum mechanics?',\n",
    "    layot=widgets.Layout(width='500px'))\n",
    "def get_correction(sentence):\n",
    "    corrected = utils.grammar_correct(sentence, grammar_model, grammar_tokenizer)\n",
    "    print(f'Original sentence: {sentence}')\n",
    "    #print(f'Answer 1: {answer_tokens_to_string}')\n",
    "    return print(f'Correction: {corrected}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact_manual(\n",
    "    question='How is angular momentum represented in quantum mechanics?', \n",
    "    context=context,\n",
    "    layot=widgets.Layout(width='500px'))\n",
    "def get_answer(question, context):\n",
    "    #answer_tokens_to_string = utils.qa_inference(qa_model, qa_tokenizer, question, context)\n",
    "    qc = {'question': question, 'context': context}\n",
    "    res = nlp(qc)\n",
    "    #answer_tokens_to_string = utils.qa_inference(qa_model, qa_tokenizer, question, context)\n",
    "    print(f'Question: {question}')\n",
    "    print()\n",
    "    print(f'Context: {context}')\n",
    "    #print(f'Answer 1: {answer_tokens_to_string}')\n",
    "    return print(f'Answer: {res[\"answer\"]}')\n",
    "\n",
    "\n",
    "# widgets.Checkbox(\n",
    "#     value=True,\n",
    "#     description='Is the answer valid?',\n",
    "#     disabled=False,\n",
    "#     indent=False\n",
    "# )\n",
    "@interact(value=['yes', 'no'])\n",
    "def is_valid(value):\n",
    "    print('Is the answer valid?')\n",
    "    v = True if value == 'yes' else False\n",
    "    return widgets.Valid(\n",
    "        layout=widgets.Layout(width='200px'),\n",
    "        value=v,\n",
    "        description='valid?',\n",
    "    )\n",
    "#     return widgets.Checkbox(\n",
    "#     value=v,\n",
    "#     description='Is the answer valid?',\n",
    "#     disabled=False,\n",
    "#     indent=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c97171bcbfabb853c7f677c58009c6eb5fb7956ea9e68d9c9c57fb3ed55f580"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venvTF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
